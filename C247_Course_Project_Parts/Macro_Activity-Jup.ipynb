{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Macro-Activity",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jPihmLbUvoa",
        "colab_type": "text"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWzF5-ugUvoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "import cv2\n",
        "import io\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import shutil\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K5fU7xrUvoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Move files into training and validation directory.\n",
        "trainfile = open('/home/nesl/swapnil/trainfileslist.csv', newline='')\n",
        "reader = csv.reader(trainfile)\n",
        "for row in reader:\n",
        "    curFile = row[0]\n",
        "    sourcepathA = '/home/nesl/swapnil/data/left_hip/'+curFile+'.csv'\n",
        "    sourcepathB = '/home/nesl/swapnil/data/right_arm/'+curFile+'.csv'\n",
        "    sourcepathC = '/home/nesl/swapnil/data/right_wrist/'+curFile+'.csv'\n",
        "    destpathA = '/home/nesl/swapnil/data_2/train/left_hip/'+curFile+'.csv'\n",
        "    destpathB = '/home/nesl/swapnil/data_2/train/right_arm/'+curFile+'.csv'\n",
        "    destpathC = '/home/nesl/swapnil/data_2/train/right_wrist/'+curFile+'.csv'\n",
        "    shutil.copy(sourcepathA,destpathA)\n",
        "    shutil.copy(sourcepathB,destpathB)\n",
        "    shutil.copy(sourcepathC,destpathC)\n",
        "    \n",
        "valfile = open('/home/nesl/swapnil/valfileslist.csv', newline='')\n",
        "reader = csv.reader(valfile)\n",
        "for row in reader:\n",
        "    curFile = row[0]\n",
        "    sourcepathA = '/home/nesl/swapnil/data/left_hip/'+curFile+'.csv'\n",
        "    sourcepathB = '/home/nesl/swapnil/data/right_arm/'+curFile+'.csv'\n",
        "    sourcepathC = '/home/nesl/swapnil/data/right_wrist/'+curFile+'.csv'\n",
        "    destpathA = '/home/nesl/swapnil/data_2/val/left_hip/'+curFile+'.csv'\n",
        "    destpathB = '/home/nesl/swapnil/data_2/val/right_arm/'+curFile+'.csv'\n",
        "    destpathC = '/home/nesl/swapnil/data_2/val/right_wrist/'+curFile+'.csv'\n",
        "    shutil.copy(sourcepathA,destpathA)\n",
        "    shutil.copy(sourcepathB,destpathB)\n",
        "    shutil.copy(sourcepathC,destpathC)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDej6DfZUvol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir_train='/home/nesl/swapnil/data_2/train'\n",
        "data_dir_val= '/home/nesl/swapnil/data_2/val'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q87cb-fJUvoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_dirs = ['left_hip','right_arm','right_wrist' ] #three sensors, 9 channels total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho3e4qQQUvor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_IMU_files(parent_dir, sub_dirs, startTime, endTime, file_name, window_length):\n",
        "    \n",
        "    data = []\n",
        "    for sub_dir in sub_dirs:\n",
        "        channel=[]\n",
        "        \n",
        "        for fn in glob.glob(os.path.join(parent_dir,sub_dir, file_name)):\n",
        "            file = open(fn, newline='')\n",
        "            reader = csv.reader(file)\n",
        "            first = True\n",
        "            count = 0\n",
        "            for row in reader:\n",
        "                \n",
        "                if first:\n",
        "                    first = False\n",
        "                    continue\n",
        "                \n",
        "                timestamp=float(row[3]) #4th column is timestamp\n",
        "                if timestamp >=startTime and timestamp <=endTime and count<window_length:\n",
        "                    \n",
        "                    channel.append([float(row[0]),float(row[1]),float(row[2])])\n",
        "                    count = count + 1  \n",
        "                    \n",
        "        data.append(channel)         \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLINn0siUvou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_data(data_dir, sub_dirs):\n",
        "    files = os.listdir(data_dir+'/left_hip')\n",
        "    number_of_samples = 300\n",
        "    \n",
        "    labels_macro =dict()\n",
        "    \n",
        "    labels_macro['sandwich'] = 0\n",
        "    labels_macro['fruitsalad'] = 1\n",
        "    labels_macro['cereal'] = 2\n",
        "    \n",
        "    \n",
        "    #read the labels\n",
        "    labels_loc = '/home/nesl/Downloads/LabelTable.csv'\n",
        "    file_label = open(labels_loc, newline='')\n",
        "    label_reader = csv.reader(file_label)\n",
        "    file_label_mapping = dict()\n",
        "    \n",
        "    for row in label_reader:\n",
        "        file_label_mapping[row[0]+'.csv'] = labels_macro[row[1]]\n",
        "        \n",
        "    all_data = []\n",
        "    all_labels = []\n",
        "    for f in files:\n",
        "        \n",
        "        st_index = 0\n",
        "        end_index = 30000\n",
        "        step = 1000 #overlapping window, step: 1000. \n",
        "        window_index = 6000 #6 second window\n",
        "        \n",
        "        print('reading file:',f)\n",
        "        f_name = f\n",
        "        \n",
        "        curr_label_file = file_label_mapping[f_name]\n",
        "        \n",
        "        while st_index+step < end_index:\n",
        "        \n",
        "            data = parse_IMU_files(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
        "            train_data_sample  = np.zeros((9, number_of_samples))\n",
        "            train_data_label   = curr_label_file\n",
        "            for i in range(len(data)):\n",
        "                for j in range(len(data[i])):\n",
        "                    train_data_sample[i*3,j]=data[i][j][0]\n",
        "                    train_data_sample[i*3+1,j]=data[i][j][1]\n",
        "                    train_data_sample[i*3+2,j]=data[i][j][2]\n",
        "            \n",
        "            all_data.append(train_data_sample)\n",
        "            all_labels.append(train_data_label)\n",
        "            \n",
        "            st_index = st_index+step\n",
        "    \n",
        "    return all_data, all_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "FEYY86nqUvoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#receive windowed training and validation data\n",
        "train_x, train_y = get_train_data(data_dir_train,sub_dirs)\n",
        "val_x, val_y = get_train_data(data_dir_val,sub_dirs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2w_y9dmUvo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samples = np.array(train_x) \n",
        "train_labels2 = np.array(train_y)\n",
        "val_samples = np.array(val_x) \n",
        "val_labels2 = np.array(val_y)\n",
        "\n",
        "#Uncomment the lines below for normalization\n",
        "#Optional: normalization\n",
        "#scalers = {}\n",
        "\n",
        "# for i in range(train_samples.shape[1]):\n",
        "#     scalers[i] = StandardScaler()\n",
        "#     train_samples[:,i,:] = scalers[i].fit_transform(train_samples[:,i,:])\n",
        "    \n",
        "# for i in range(val_samples.shape[1]):\n",
        "#     val_samples[:,i,:] = scalers[i].transform(val_samples[:,i,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNUKXbk9Uvo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_samples.shape)\n",
        "print(train_labels2.shape)\n",
        "print(val_samples.shape)\n",
        "print(val_labels2.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1OiMsBOUvo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to one hot encoding\n",
        "from keras.utils  import to_categorical\n",
        "train_labels = to_categorical(train_labels2)\n",
        "train_labels.shape\n",
        "val_labels = to_categorical(val_labels2)\n",
        "val_labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d-H-X42Uvo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_samples.shape)\n",
        "print(train_labels.shape)\n",
        "print(val_samples.shape)\n",
        "print(val_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqxij4vFUvo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For CNN and BidirLSTM:\n",
        "train_samples = train_samples.reshape((-1, 9,number_of_samples, 1))\n",
        "val_samples = val_samples.reshape((-1, 9,number_of_samples, 1))\n",
        "#For LSTM, uncomment these lines and comment above two lines\n",
        "#train_samples = train_samples.reshape((-1, number_of_samples, 9))\n",
        "#val_samples = val_samples.reshape((-1, number_of_samples, 9))\n",
        "\n",
        "#9 refers to 9 accelerometer channels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf0eewtJUvpB",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyNXsGAAUvpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, Flatten, Bidirectional\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.core import Permute, Reshape\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKNc7WZQUvpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _data_reshaping(X_tr, X_va, X_ts, network_type):\n",
        "    _, win_len, dim = X_tr.shape\n",
        "    print(network_type)\n",
        "    if network_type=='CNN' or network_type=='ConvLSTM':\n",
        "\n",
        "        X_tr = np.swapaxes(X_tr,1,2)\n",
        "        X_va = np.swapaxes(X_va,1,2)\n",
        "        X_ts = np.swapaxes(X_ts,1,2)\n",
        "\n",
        "        X_tr = np.reshape(X_tr, (-1, dim, win_len, 1))\n",
        "        X_va = np.reshape(X_va, (-1, dim, win_len, 1))\n",
        "        X_ts = np.reshape(X_ts, (-1, dim, win_len, 1))\n",
        "    \n",
        "    return X_tr, X_va, X_ts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcMCdtFUUvpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_variant(model, num_feat_map, dim, network_type,p):\n",
        "    print(network_type)\n",
        "    if network_type == 'ConvLSTM':\n",
        "        model.add(Permute((2, 1, 3))) \n",
        "        model.add(Reshape((-1,num_feat_map*dim)))\n",
        "        model.add(Bidirectional(LSTM(128, return_sequences=False, stateful=False)))\n",
        "    if network_type == 'CNN':\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(BatchNormalization()) \n",
        "        model.add(Dropout(p))\n",
        "\n",
        "        \n",
        "def model_conv(model, num_feat_map,p,b):\n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10),    \n",
        "                 activation='relu',\n",
        "                 input_shape=(dim, win_len, 1),\n",
        "                 padding='same'))\n",
        "    \n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10), activation='relu',padding='same'))\n",
        "    \n",
        "    if (b==1):\n",
        "        model.add(BatchNormalization()) \n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10), activation='relu',padding='same'))\n",
        "    \n",
        "    if (b==1):\n",
        "        model.add(BatchNormalization()) \n",
        "    model.add(MaxPooling2D(pool_size=(1, 3)))\n",
        "    \n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10), activation='relu',padding='same')) \n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10), activation='relu',padding='same'))\n",
        "    if (b==1):\n",
        "        model.add(BatchNormalization()) \n",
        "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
        "    model.add(Dropout(p))\n",
        "    \n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10), activation='relu',padding='same'))  \n",
        "    if (b==1):\n",
        "        model.add(BatchNormalization()) \n",
        "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
        "    \n",
        "    model.add(Dropout(p))\n",
        "    \n",
        "def model_LSTM(model,p):\n",
        "    model.add(LSTM(num_hidden_lstm, \n",
        "               input_shape=(win_len,dim), \n",
        "               return_sequences=True))\n",
        "    model.add(Dropout(p))\n",
        "    model.add(LSTM(num_hidden_lstm, return_sequences=False))\n",
        "    model.add(Dropout(p))\n",
        "    \n",
        "def model_output(model):\n",
        "    model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf8LuDxlUvpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "num_feat_map = 128\n",
        "num_hidden_lstm = 128\n",
        "num_classes = 3\n",
        "\n",
        "#Uncomment the classifier you are working with:\n",
        "#network_type = 'CNN'\n",
        "network_type = 'ConvLSTM'\n",
        "#network_type = 'LSTM'\n",
        "#for CNN/DCBL\n",
        "_, dim, win_len,_ = train_samples.shape\n",
        "#for LSTM uncomment the following line and comment above line\n",
        "#_, dim, win_len = train_samples.shape\n",
        "\n",
        "print(win_len)\n",
        "print(dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAQRf1DNUvpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p=0.5 #Dropout\n",
        "b = 1 #BatchNorm\n",
        "print('building the model ... ')\n",
        "model = Sequential()\n",
        "\n",
        "if network_type=='CNN' or network_type=='ConvLSTM':\n",
        "    model_conv(model, num_feat_map,p,b)\n",
        "    model_variant(model, num_feat_map, dim, network_type,p)\n",
        "if network_type=='LSTM':\n",
        "    model_LSTM(model,p)\n",
        "       \n",
        "model_output(model)    \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrNCEAD8UvpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train_samples\n",
        "y_train = train_labels\n",
        "X_val = val_samples\n",
        "y_val = val_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNsDOBNrUvpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape, X_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YpsJRPEfUvpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 200\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# checkpoint\n",
        "filepath=\"DCBL_6_NoMocap.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "H = model.fit(train_samples, train_labels,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            shuffle=True,\n",
        "            validation_data=(X_val, y_val),\n",
        "             callbacks=callbacks_list\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ASUmtFSUvpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = H"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6yi5aaJUvpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "print(np.argmax(np.array(history.history['val_acc'])))\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "print('Maximum validation accuracy: ',np.max(np.array(history.history['val_acc'])))\n",
        "print('Training accuracy of best model: ',np.array(history.history['acc'])[np.argmax(np.array(history.history['val_acc']))])\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}